{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gb_NLP_les7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8FsvOED8UlF"
      },
      "source": [
        "# Урок 7. Сверточные нейронные сети для анализа текста\n",
        "\n",
        "Задание\n",
        "Берем отызывы за лето (из архива с материалами или предыдущего занятия)\n",
        "- Учим conv сеть для классификации\n",
        "- Рассмотреть 2-а варианта сеточек\n",
        "  - Инициализировать tf.keras.layers.Embedding предобученными векторами взять к примеру с https://rusvectores.org/ru/\n",
        "  - Инициализировать слой tf.keras.layers.Embedding по умолчанию (ну то есть вам ничего не делать с весами)\n",
        "- Сравнить две архитектуры с предобученными весами и когда tf.keras.layers.Embedding обучается сразу со всей сеточкой, что получилось лучше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eHK0K1Lw6nb"
      },
      "source": [
        "## Задача (Sentiment Analysis)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpMppjiRfC58",
        "outputId": "e0da7430-bf5c-45f7-c12a-37f602a63ccc"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKqWeTUsizSI"
      },
      "source": [
        "max_words = 200\n",
        "max_len = 40\n",
        "num_classes = 1\n",
        "epochs = 20\n",
        "batch_size = 512\n",
        "print_batch_n = 100"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUCk-5M2yg3S"
      },
      "source": [
        "url = '/content/drive/MyDrive/Colab Notebooks/data/gb_NLP_les7_data/'\n",
        "\n",
        "df_train = pd.read_csv(url + 'data/train.csv')\n",
        "df_test = pd.read_csv(url + 'data/test.csv')\n",
        "df_val = pd.read_csv(url + 'data/val.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KBSf-OfDzWOI",
        "outputId": "5f15b949-48e0-4b12-900f-553efa38de86"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  class\n",
              "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
              "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
              "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
              "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
              "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "LuZtq9cwIvMt",
        "outputId": "7e57caf5-10ad-47ba-874e-b932b1b2f5b5"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>204150</td>\n",
              "      <td>Тектоника и рельеф-самое ужасное в мире мучение(</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>204151</td>\n",
              "      <td>Ходили запускать шар желаний, но у нас не полу...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>204152</td>\n",
              "      <td>Хочу лето только ради того, что бы направить н...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>204153</td>\n",
              "      <td>RT @RonyLiss: @colf_ne блин((\\nа я шипперила Ф...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>204154</td>\n",
              "      <td>RT @anna_romt: @ZADROT_PO_IGRAM блин,каждое во...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                               text\n",
              "0  204150   Тектоника и рельеф-самое ужасное в мире мучение(\n",
              "1  204151  Ходили запускать шар желаний, но у нас не полу...\n",
              "2  204152  Хочу лето только ради того, что бы направить н...\n",
              "3  204153  RT @RonyLiss: @colf_ne блин((\\nа я шипперила Ф...\n",
              "4  204154  RT @anna_romt: @ZADROT_PO_IGRAM блин,каждое во..."
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_9l0iHhaI0O1",
        "outputId": "c7161327-d78a-43ec-c2f3-8028f63e9c6b"
      },
      "source": [
        "df_val.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>181467</td>\n",
              "      <td>RT @TukvaSociopat: Максимальный репост! ))) #є...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>181468</td>\n",
              "      <td>чтоб у меня з.п. ежегодно индексировали на инд...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>181469</td>\n",
              "      <td>@chilyandlime нехуя мне не хорошо !!! :((((</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>181470</td>\n",
              "      <td>@inafish нее , когда ногами ахахах когда?ахаха...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>181471</td>\n",
              "      <td>Хочу сделать как лучше,  а получаю как всегда. :(</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                               text  class\n",
              "0  181467  RT @TukvaSociopat: Максимальный репост! ))) #є...      1\n",
              "1  181468  чтоб у меня з.п. ежегодно индексировали на инд...      0\n",
              "2  181469        @chilyandlime нехуя мне не хорошо !!! :((((      0\n",
              "3  181470  @inafish нее , когда ногами ахахах когда?ахаха...      0\n",
              "4  181471  Хочу сделать как лучше,  а получаю как всегда. :(      0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEyvOxoOJDTP"
      },
      "source": [
        "## Предобработка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SaY1AmQsIpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10f5ee0-794d-401b-ff0f-17412c15c839"
      },
      "source": [
        "!pip install stop_words pymorphy2\n",
        "\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stop_words in /usr/local/lib/python3.7/dist-packages (2018.7.23)\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkzLLsk7sIpq"
      },
      "source": [
        "sw = set(get_stop_words(\"ru\"))\n",
        "exclude = set(punctuation)\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
        "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
        "df_test['text'] = df_test['text'].apply(preprocess_text)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4o9QgmWI3Pw"
      },
      "source": [
        "train_corpus = \" \".join(df_train[\"text\"])\n",
        "train_corpus = train_corpus.lower()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hed2ySbwJH6B",
        "outputId": "2849b45e-317f-4c3a-d000-31ac50f141b2"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "tokens = word_tokenize(train_corpus)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ8T0fwYJYJX"
      },
      "source": [
        "### Фильтрация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXOLVK1tJLT8"
      },
      "source": [
        "tokens_filtered = [word for word in tokens if word.isalnum()]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qCQH5nIJoiB"
      },
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "dist = FreqDist(tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRQ-6wwjJrGo",
        "outputId": "bcc31abe-7df0-451a-a734-c20319b806fc"
      },
      "source": [
        "tokens_filtered_top[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rt',\n",
              " 'd',\n",
              " 'хотеть',\n",
              " 'знать',\n",
              " 'ян',\n",
              " 'мочь',\n",
              " 'новый',\n",
              " 'любить',\n",
              " 'завтра',\n",
              " 'мой']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdk777qGJtz4"
      },
      "source": [
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OULZgvkJzpj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def text_to_sequence(text, maxlen):\n",
        "    result = []\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "    for word in tokens_filtered:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "    padding = [0]*(maxlen-len(result))\n",
        "    return padding + result[-maxlen:]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqHlf5nNJ2hl"
      },
      "source": [
        "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"text\"]], dtype=np.int32)\n",
        "x_test = np.asarray([text_to_sequence(text, max_len) for text in df_test[\"text\"]], dtype=np.int32)\n",
        "x_val = np.asarray([text_to_sequence(text, max_len) for text in df_val[\"text\"]], dtype=np.int32)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI4NUg_TJ6NK",
        "outputId": "1e34e567-5194-4395-dc36-ac36044d664d"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(181467, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEb90AIlsIpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd02780-ba2f-46ca-cfe1-3ecfebb91968"
      },
      "source": [
        "max_len"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QlLvXd9KDf3",
        "outputId": "13f63b34-473b-4b75-be18-a0be9707058b"
      },
      "source": [
        "x_train[1]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 170,\n",
              "         9], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKfNHYQcsIp0"
      },
      "source": [
        "# Keras model (default)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fl0eHJusIp1"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import TensorBoard \n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwSAxR-ssIp1"
      },
      "source": [
        "num_classes = 2\n",
        "y_train = to_categorical(df_train[\"class\"], num_classes)\n",
        "y_val = to_categorical(df_val[\"class\"], num_classes)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2i_QrhssIp2"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
        "model.add(Conv1D(128, 3))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWE-GLNGsIp2"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M4yzAabsIp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4638b1c1-6517-41e6-c315-b7bcca1d3b6a"
      },
      "source": [
        "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard, early_stopping])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "319/319 [==============================] - 50s 154ms/step - loss: 0.6276 - accuracy: 0.6150 - val_loss: 0.6177 - val_accuracy: 0.6223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XELRRRJNsIp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56702a8d-8f05-4ae2-995a-e939bb698d85"
      },
      "source": [
        "score = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=1)\n",
        "\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 2s 39ms/step - loss: 0.6201 - accuracy: 0.6221\n",
            "\n",
            "\n",
            "Test score: 0.620079517364502\n",
            "Test accuracy: 0.6221399307250977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1QY9g0OmfOE"
      },
      "source": [
        "## Keras model with weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtqppQGcsr3V"
      },
      "source": [
        "import wget\n",
        "\n",
        "udpipe_url = 'https://rusvectores.org/static/models/udpipe_syntagrus.model'\n",
        "modelfile = wget.download(udpipe_url)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}