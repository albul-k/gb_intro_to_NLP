{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gb_NLP_les8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgGRwyh8bseo"
      },
      "source": [
        "# Урок 8. Рекуррентные нейронные сети RNN LSTM GRU\n",
        "\n",
        "## Задание\n",
        "\n",
        "* построить свёрточные архитектуры\n",
        "* построить различные архитектуры с RNN\n",
        "* построить совместные архитектуры CNN -> RNN и (RNN -> CNN)\n",
        "* сделать выводы что получилось лучше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D9RxFkyc7Dq"
      },
      "source": [
        "## Загрузка библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvF27pT5cELA",
        "outputId": "b1b46fe5-9cc1-43cd-fefe-bdd10188d961"
      },
      "source": [
        "!pip install stop_words pymorphy2\n",
        "\n",
        "import pandas as pd\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import TensorBoard \n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stop_words in /usr/local/lib/python3.7/dist-packages (2018.7.23)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "85cdDJbGc0nO",
        "outputId": "652d0bc8-0887-480f-82d8-582d480a3097"
      },
      "source": [
        "url = '/content/drive/MyDrive/Colab Notebooks/data/gb_NLP_les7_data/'\n",
        "\n",
        "df_train = pd.read_csv(url + 'data/train.csv')\n",
        "df_test = pd.read_csv(url + 'data/test.csv')\n",
        "df_val = pd.read_csv(url + 'data/val.csv')\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  class\n",
              "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
              "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
              "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
              "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
              "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAlebGvycTum"
      },
      "source": [
        "sw = set(get_stop_words(\"ru\"))\n",
        "exclude = set(punctuation)\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
        "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
        "df_test['text'] = df_test['text'].apply(preprocess_text)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ44qnC6dW0x"
      },
      "source": [
        "## Предобработка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rp39nDqcXHT"
      },
      "source": [
        "text_corpus_train = df_train['text'].values\n",
        "text_corpus_valid = df_val['text'].values\n",
        "text_corpus_test = df_test['text'].values"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtNc71z_cYbR"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=None, \n",
        "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
        "                     lower = False, split = ' ')\n",
        "tokenizer.fit_on_texts(text_corpus_train)\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
        "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
        "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
        "\n",
        "word_count = len(tokenizer.index_word) + 1\n",
        "training_length = max([len(i.split()) for i in text_corpus_train])\n",
        "\n",
        "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
        "X_valid = pad_sequences(sequences_val, maxlen=training_length)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp3_8twZcaSy"
      },
      "source": [
        "y_train = df_train['class'].values\n",
        "y_val = df_val['class'].values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T02CVybddwQ"
      },
      "source": [
        "## SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsP5ZB5scbuv"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "  Embedding(input_dim=word_count,\n",
        "            input_length=training_length,\n",
        "            output_dim=30,\n",
        "            trainable=True,\n",
        "            mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss='binary_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoNxYSZtcdRK",
        "outputId": "0fbf6cbd-82ea-4e29-f638-1911b579fb51"
      },
      "source": [
        "early_stopping=EarlyStopping(monitor='val_loss')\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 27s 80ms/step - loss: 0.5589 - accuracy: 0.6969 - val_loss: 0.4949 - val_accuracy: 0.7568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lg74QGQcfC_",
        "outputId": "4deb0bd0-6a0e-47fc-b238-7b002065b806"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 0s 7ms/step - loss: 0.5087 - accuracy: 0.7425\n",
            "\n",
            "\n",
            "Test score: 0.5086950063705444\n",
            "Test accuracy: 0.7424502968788147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmmo-KoUdhFf"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9irz7NRciVU",
        "outputId": "6d0896d6-55fe-480d-ec55-be0de0853cbf"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "  Embedding(input_dim=word_count,\n",
        "            input_length=training_length,\n",
        "            output_dim=30,\n",
        "            trainable=True,\n",
        "            mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(LSTM(64, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss='binary_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/10\n",
            "319/319 [==============================] - 76s 227ms/step - loss: 0.5572 - accuracy: 0.7045 - val_loss: 0.4930 - val_accuracy: 0.7563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_cLiAqAclgk",
        "outputId": "ca5b7301-7e75-409e-df75-aee2710842af"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 1s 15ms/step - loss: 0.5174 - accuracy: 0.7412\n",
            "\n",
            "\n",
            "Test score: 0.517432451248169\n",
            "Test accuracy: 0.7412158846855164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1USrY7Jdjzm"
      },
      "source": [
        "## GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckFLjSspcnur",
        "outputId": "2aa407f7-72d8-421a-af21-034eb191ace8"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "  Embedding(input_dim=word_count,\n",
        "            input_length=training_length,\n",
        "            output_dim=30,\n",
        "            trainable=True,\n",
        "            mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(GRU(64, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss='binary_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/10\n",
            "319/319 [==============================] - 66s 198ms/step - loss: 0.5521 - accuracy: 0.7086 - val_loss: 0.4904 - val_accuracy: 0.7559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWKYecq-cquS",
        "outputId": "9c2abc69-44f4-4fa6-9b5c-5a298c2b5725"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 1s 14ms/step - loss: 0.5188 - accuracy: 0.7392\n",
            "\n",
            "\n",
            "Test score: 0.5187957882881165\n",
            "Test accuracy: 0.7391879558563232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiNElGqljh3W"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaZZ2kP7jgnv",
        "outputId": "84cd00e8-34e8-4d91-96e5-010694b73623"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "  Embedding(input_dim=word_count,\n",
        "            input_length=training_length,\n",
        "            output_dim=30,\n",
        "            trainable=True,\n",
        "            mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(LSTM(256, return_sequences=\"True\"))\n",
        "model.add(Conv1D(128, 3))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss='binary_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_19 (Embedding)     (None, 27, 30)            7743240   \n",
            "_________________________________________________________________\n",
            "masking_19 (Masking)         (None, 27, 30)            0         \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 27, 256)           293888    \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 25, 128)           98432     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 25, 128)           0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_8 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 8,211,849\n",
            "Trainable params: 8,211,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dNXOUY-mKp9",
        "outputId": "adaf564b-196e-44e8-edf1-197f3aa2b34a"
      },
      "source": [
        "early_stopping=EarlyStopping(monitor='val_loss')\n",
        "\n",
        "hh = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 22s 54ms/step - loss: 0.5514 - accuracy: 0.7058 - val_loss: 0.4835 - val_accuracy: 0.7592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYqPyN60j36D",
        "outputId": "0169d07f-21be-44e4-8623-6e09012e0e3b"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 1s 16ms/step - loss: 0.5141 - accuracy: 0.7380\n",
            "\n",
            "\n",
            "Test score: 0.514101505279541\n",
            "Test accuracy: 0.7379535436630249\n"
          ]
        }
      ]
    }
  ]
}